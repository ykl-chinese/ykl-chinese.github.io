<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>我的UE4地编作品</title>
      <link href="/2023/09/14/%E6%88%91%E7%9A%84UE4%E5%9C%B0%E7%BC%96%E4%BD%9C%E5%93%81/"/>
      <url>/2023/09/14/%E6%88%91%E7%9A%84UE4%E5%9C%B0%E7%BC%96%E4%BD%9C%E5%93%81/</url>
      
        <content type="html"><![CDATA[<p>使用到的软件：虚幻4，Maya, Substance Painter，Substance Designer</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/%E8%A1%97%E5%A4%B4.png" alt></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>我的PBR流程建模作品</title>
      <link href="/2023/09/14/%E6%88%91%E7%9A%84PBR%E6%B5%81%E7%A8%8B%E5%BB%BA%E6%A8%A1%E4%BD%9C%E5%93%81/"/>
      <url>/2023/09/14/%E6%88%91%E7%9A%84PBR%E6%B5%81%E7%A8%8B%E5%BB%BA%E6%A8%A1%E4%BD%9C%E5%93%81/</url>
      
        <content type="html"><![CDATA[<p>使用到的软件：3DsMax,Maya, ZBrush , Substance Painter</p><p>其实做的并不好看，更多的是展示自己做过的完整建模流程。</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/2012%E6%9C%9F%E5%BA%94%E5%9D%A4%E9%BE%9901.jpg" alt></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/2012%E6%9C%9F%E5%BA%94%E5%9D%A4%E9%BE%9903.jpg" alt></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/2012%E6%9C%9F%E5%BA%94%E5%9D%A4%E9%BE%9902.jpg" alt><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/2012%E6%9C%9F%E5%BA%94%E5%9D%A4%E9%BE%9904.jpg" alt></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>小练习:一个像素风格的溶解</title>
      <link href="/2023/08/24/%E5%B0%8F%E7%BB%83%E4%B9%A0%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%83%8F%E7%B4%A0%E9%A3%8E%E6%A0%BC%E7%9A%84%E6%BA%B6%E8%A7%A3/"/>
      <url>/2023/08/24/%E5%B0%8F%E7%BB%83%E4%B9%A0%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%83%8F%E7%B4%A0%E9%A3%8E%E6%A0%BC%E7%9A%84%E6%BA%B6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>关键词：像素化</p><p>刷推特刷到一个效果，蛮有意思的。尝试一下</p><p>博主链接：<a href="https://twitter.com/i/status/1694492782247698881">https://twitter.com/i/status/1694492782247698881</a></p><p>核心方法只有一行：floor(value*steps)/steps;</p><p>核心思路是把上面的算法用在UV参数上，从而可以把噪声像素化，甚至可以用在时间参数上，来调整”帧率“</p><p>下面是依据博主的思路做的类似的简单效果。可以调整像素数量与大小，边框粗细，时间参数等。</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/%E5%83%8F%E7%B4%A0%E6%BA%B6%E8%A7%A3.gif" alt></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/%E5%8A%A8%E7%94%BB2.gif" alt></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>备忘录：Bloom的实现与优化</title>
      <link href="/2023/08/22/Bloom2/"/>
      <url>/2023/08/22/Bloom2/</url>
      
        <content type="html"><![CDATA[<p>这篇文章是很久之前，在公司项目中实现Bloom的时候整理的，当时是为了做哥归纳，顺便给同事做分享。</p><p>主要参考的是知乎的一篇文章，写的相当不错。关于模糊算法参考了毛星云的模糊算法文章。</p><h1 id="什么样的Bloom是好看的"><a href="#什么样的Bloom是好看的" class="headerlink" title="什么样的Bloom是好看的"></a>什么样的Bloom是好看的</h1><h2 id="光晕要足够大"><a href="#光晕要足够大" class="headerlink" title="光晕要足够大"></a>光晕要足够大</h2><p>下图是光晕太小的结果</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/bloom1.jpg" alt></p><h2 id="不该亮的地方不亮亮"><a href="#不该亮的地方不亮亮" class="headerlink" title="不该亮的地方不亮亮"></a>不该亮的地方不亮亮</h2><p>不该亮的地方亮，画面会很脏</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/bloom2.jpg" alt></p><h2 id="光晕的亮度要有渐变"><a href="#光晕的亮度要有渐变" class="headerlink" title="光晕的亮度要有渐变"></a>光晕的亮度要有渐变</h2><p>没渐变的光源看上去非常违和</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/bloom3.jpg" alt></p><h1 id="影响光晕大小的因素"><a href="#影响光晕大小的因素" class="headerlink" title="影响光晕大小的因素"></a>影响光晕大小的因素</h1><h2 id="1，模糊卷积核的大小"><a href="#1，模糊卷积核的大小" class="headerlink" title="1，模糊卷积核的大小"></a>1，模糊卷积核的大小</h2><p>如果卷积核的大越大，高亮颜色所影响的范围就越大，即光晕越大</p><h2 id="2，模糊次数"><a href="#2，模糊次数" class="headerlink" title="2，模糊次数"></a>2，模糊次数</h2><p>模糊次数越多，高亮颜色扩散的范围就越大，即光晕越大</p><h2 id="3，颜色强度"><a href="#3，颜色强度" class="headerlink" title="3，颜色强度"></a>3，颜色强度</h2><p>当颜色强度比较弱，颜色可能在模糊的过程中很快的被“分”完，影响光晕的大小</p><h1 id="如何让光晕有渐变"><a href="#如何让光晕有渐变" class="headerlink" title="如何让光晕有渐变"></a>如何让光晕有渐变</h1><p>在逐渐模糊画面去做bloom的扩散的过程中，也就得到了一组范围逐渐扩大的亮度信息。</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/bloom4.jpg" alt></p><p>那么如果我们把这些信息进行叠加，就可以得到一个类似高随分布的bloom，也就有了我们想要的渐变过程</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/bloom5.jpg" alt></p><p>左边是只保留最后的扩散结果的效果，右边是进行叠加的效果。</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/bloom6.jpg" alt></p><h2 id="大致实现流程"><a href="#大致实现流程" class="headerlink" title="大致实现流程"></a>大致实现流程</h2><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/bloom7.jpg" alt></p><h2 id="为何选择升降采样"><a href="#为何选择升降采样" class="headerlink" title="为何选择升降采样"></a>为何选择升降采样</h2><p>这是一个优化方案，我们在进行模糊的时候，会使用到 贴图名_TexelSize的数据，是一个四维向量，前两个值是宽高的倒数，后两个值是宽高，我们会只用前两个值去偏移UV。那么显而易见的是，如果贴图尺寸越小，我们偏移的就越快。并且模糊的时候扩散的相对范围就越广。也就更加快速的达到了我们增加模糊范围的目的。既节约了带宽，也提高了效率。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.jianshu.com/p/f27bb99368c9">https://www.jianshu.com/p/f27bb99368c9</a></p><p><a href="https://zhuanlan.zhihu.com/p/525500877">https://zhuanlan.zhihu.com/p/525500877</a></p><p><a href="https://zhuanlan.zhihu.com/p/125744132">https://zhuanlan.zhihu.com/p/125744132</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>基于SRP复刻《动物派对》</title>
      <link href="/2023/08/22/%E5%9F%BA%E4%BA%8ESRP%E5%A4%8D%E5%88%BB%E3%80%8A%E5%8A%A8%E7%89%A9%E6%B4%BE%E5%AF%B9%E3%80%8B/"/>
      <url>/2023/08/22/%E5%9F%BA%E4%BA%8ESRP%E5%A4%8D%E5%88%BB%E3%80%8A%E5%8A%A8%E7%89%A9%E6%B4%BE%E5%AF%B9%E3%80%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>《动物派对》马上就要上线了，我很喜欢这款游戏,这次的china joy上还买到了他们的周边哈哈哈，真可爱。</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/_20230822035433.jpg" alt></p><p>最近在家，打算做一个相对完成的渲染流程，就选择《动物派对》进行复刻啦！</p><p>选择《动物派对》的理由有几点：</p><p>1，渲染风格是我个人喜欢的类型</p><p>2，美术资源的获取相对简单</p><p>3，延迟渲染管线是我个人之前没有搭建过的，正好学习</p><p>选择写文章记录下来，目的是分享和展示，以及自己备忘。</p><h1 id="《动物派对》截帧分析与渲染技术点罗列"><a href="#《动物派对》截帧分析与渲染技术点罗列" class="headerlink" title="《动物派对》截帧分析与渲染技术点罗列"></a>《动物派对》截帧分析与渲染技术点罗列</h1><p>下载了之前官方测试时候的Demo。用RenderDoc截了几帧。</p><p>这里单纯罗列使用到了哪些技术。</p><h2 id="渲染管线类型"><a href="#渲染管线类型" class="headerlink" title="渲染管线类型"></a>渲染管线类型</h2><p>延迟渲染</p><p>整体的思路和unity urp的大同小异。</p><h2 id="GBuffer"><a href="#GBuffer" class="headerlink" title="GBuffer"></a>GBuffer</h2><p>Gbuffer一共五张Render Texture</p><p>Gbuffer A ：RGB 是非金属 的Albedo ，A 通道为AO</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/10.jpg" alt></p><p>GBuffer B：RGB是世界空间法线</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/11.jpg" alt></p><p>GBuffer C：RGB是金属的Albedo，A是粗糙度</p><p>GBuffer D:  烘培了的阴影Mask的物体 会渲染进 R通道，其他没有烘培光影的动态物体 会输入RGBA。</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/12.jpg" alt></p><p>（Buffer A 与C 之所以要分成两种 Albedo，从渲染公式角度讲，金属度越高，漫反射越少。）</p><p>（Buffer A 与C 的 Albedo 使用金属度 进行了权重分配）</p><h2 id="地形材质"><a href="#地形材质" class="headerlink" title="地形材质"></a>地形材质</h2><p>游戏中战斗的地面是可以进行材质混合的地形材质。可以进行草地，泥土，砖块三种材质的混合。也是使用贴图最多的材质。算上光照贴图和shadowMask，用了十张图。</p><p>材质的混合使用顶点色配合贴图中的高度图通道进行。</p><h2 id="阴影方案："><a href="#阴影方案：" class="headerlink" title="阴影方案："></a>阴影方案：</h2><p>游戏使用了级联阴影，阴影图的大小是4096*4096.</p><h2 id="人物渲染"><a href="#人物渲染" class="headerlink" title="人物渲染"></a>人物渲染</h2><p>有毛发的动物，毛发方案是多pass实现的。</p><h2 id="抗锯齿方案："><a href="#抗锯齿方案：" class="headerlink" title="抗锯齿方案："></a>抗锯齿方案：</h2><p>TAA</p><h2 id="全局光方案："><a href="#全局光方案：" class="headerlink" title="全局光方案："></a>全局光方案：</h2><p>HBAO+shadowMask图+LightMap+光照探针+反射探针</p><h2 id="HBAO"><a href="#HBAO" class="headerlink" title="HBAO"></a>HBAO</h2><p>HBAO前后区别</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/6.jpg" alt></p><p>Light Map与shadow Mask</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/image-20230821115129822.png" alt></p><h2 id="运动模糊"><a href="#运动模糊" class="headerlink" title="运动模糊"></a>运动模糊</h2><p>只给动物加了运动模糊</p><h2 id="其他后处理：Chromatic-Aberration-Bloom-景深-色调映射"><a href="#其他后处理：Chromatic-Aberration-Bloom-景深-色调映射" class="headerlink" title="其他后处理：Chromatic Aberration + Bloom +景深 +色调映射"></a>其他后处理：Chromatic Aberration + Bloom +景深 +色调映射</h2><h3 id="Chromatic-Aberration"><a href="#Chromatic-Aberration" class="headerlink" title="Chromatic Aberration"></a>Chromatic Aberration</h3><blockquote><h2 id="What-is-chromatic-aberration"><a href="#What-is-chromatic-aberration" class="headerlink" title="What is chromatic aberration?"></a>What is chromatic aberration?</h2><p>Chromatic aberration, also known as color fringing, is a color distortion that creates an outline of unwanted color along the edges of objects in a photograph. Often, it appears along metallic surfaces or where there’s a high contrast between light and dark objects, such as a black wall in front of a bright blue sky. Each type of aberration causes different colors of outlines along an object’s edge.</p><p>The failure of a camera lens to focus each of white light’s different wavelengths onto the same focal point may lead to blue-yellow, red-green, or magenta-purple fringing. This is due to the refractive index of glass; various wavelengths of light travel through the lens at different speeds, making it difficult for some lenses to focus each hue on the same focal plane.</p><p>什么是色差？</p><p>色差，也被称为彩色边缘，是一种颜色失真，沿着照片中物体的边缘产生不需要的颜色轮廓。通常，它出现在金属表面，或者明暗物体之间有很高对比度的地方，比如明亮的蓝天前的黑墙。每种类型的像差都会导致物体边缘的轮廓颜色不同。</p><p>相机镜头无法将不同波长的白光中的每一个聚焦到同一焦点上，可能会导致蓝黄、红绿或品红色-紫色边缘。这是由于玻璃的折射率；不同波长的光以不同的速度穿过透镜，使得一些透镜难以将每个色调聚焦在同一焦平面上。</p></blockquote><p>下图中的内容是场景中的球拍。左边是原图，右边是进行了处理之后的效果</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/9.jpg" alt></p><p>下图是整体画面的前后变化。</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/8.jpg" alt></p><h3 id="色调映射"><a href="#色调映射" class="headerlink" title="色调映射"></a>色调映射</h3><p>这个调色对于整体风格起到了非常重要的作用</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/7.jpg" alt></p><p>罗列完技术点之后，就可以正式开始复刻</p><h1 id="美术资源获取"><a href="#美术资源获取" class="headerlink" title="美术资源获取"></a>美术资源获取</h1><p>动物派对的demo没有做任何加密，很简单就可以用RenderDoc截取，大部分贴图资源我都是直接从RenderDoc中导出。关于模型资源，主要使用的是ninja ripper 2来得到，不过不是那么好用，花了不少时间去整理素材。而且还出来了法线反了的情况，需要一个个调整之后再导入到引擎，不是那么友好。另外，还使用了市面上的一些renderDoc模型导出插件，把csv格式转换为FBX格式，不过也偶尔会出一些问题，不过再两个软件的搭配下勉强算是把美术资源搞定了。之后有时间也有研究一下RenderDoc插件的想法，听说可以实现直接把整个场景导出，听着非常吸引人。</p><h1 id="PreZ"><a href="#PreZ" class="headerlink" title="PreZ"></a>PreZ</h1><p>《动物派对》游戏本身是没有使用Pre Z去处理植物的，也许是因为渲染压力并没有这么大，并且植物也没有造成大量的遮挡。</p><p>但是我在demo中还是使用了，只是单纯因为想练练手（笑）。如果是项目中，需要权衡开销以及需求等等问题。</p><p>PreZ Pass中，执行的是和depth only pass中相同的shader pass，区别是，depth only pass 的渲染目标是一张单独的深度图，而PreZ的目标与GBuffer填充阶段是相同的。并且只会渲染部分特定的物体。PreZ Pass只会渲染”Paints“层级下的物体。</p><h1 id="unity时间参数的问题"><a href="#unity时间参数的问题" class="headerlink" title="unity时间参数的问题"></a>unity时间参数的问题</h1><p>目前我在unity2019.4和2021.3版本中都发现时间参数需要传递两次。</p><p>按照注释说的，是  context.SetupCameraProperties(camera);这个设置矩阵的函数影响了时间参数。说实话我没搞懂，就姑且无脑按照官方说的做了，目前我暂时也没发现有啥问题。</p><p>下面是官方urp的源码片段。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">// Initialize Camera Render State</span><br><span class="line"> ClearRenderingState(cmd);</span><br><span class="line"> SetShaderTimeValues(cmd, time, deltaTime, smoothDeltaTime);</span><br><span class="line">。</span><br><span class="line">。</span><br><span class="line">。</span><br><span class="line">其他代码</span><br><span class="line">。</span><br><span class="line">。</span><br><span class="line">。</span><br><span class="line"> if (cameraData.renderType == CameraRenderType.Base)</span><br><span class="line">&#123;</span><br><span class="line">    context.SetupCameraProperties(camera);</span><br><span class="line">    SetPerCameraShaderVariables(cmd, ref cameraData);</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    // Set new properties</span><br><span class="line">    SetPerCameraShaderVariables(cmd, ref cameraData);</span><br><span class="line">    SetPerCameraClippingPlaneProperties(cmd, in cameraData);</span><br><span class="line">    SetPerCameraBillboardProperties(cmd, ref cameraData);</span><br><span class="line">&#125;</span><br><span class="line"> // Reset shader time variables as they were overridden in SetupCameraProperties. If we don&#x27;t do it we might have a mismatch between shadows and main rendering</span><br><span class="line"> SetShaderTimeValues(cmd, time, deltaTime, smoothDeltaTime);</span><br></pre></td></tr></table></figure><h1 id="GBuffer填充"><a href="#GBuffer填充" class="headerlink" title="GBuffer填充"></a>GBuffer填充</h1><p>在我自己渲染的过程中，GBuffer阶段算上深度缓存，一共需要输出6张Render Texture</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GBuffers[0] = Shader.PropertyToID(&quot;_GBuffer_Albedo&quot;);</span><br><span class="line">GBuffers[1] = Shader.PropertyToID(&quot;_GBuffer_Normal&quot;);</span><br><span class="line">GBuffers[2] = Shader.PropertyToID(&quot;_GBuffer_SpecularSmoothness&quot;);</span><br><span class="line">GBuffers[3] = Shader.PropertyToID(&quot;_GBuffer_GI&quot;); </span><br><span class="line">GBuffers[4] = Shader.PropertyToID(&quot;_GBuffer_ShadowMask&quot;);</span><br><span class="line">GDepth = Shader.PropertyToID(&quot;_GDepth&quot;);</span><br></pre></td></tr></table></figure><p>_GBuffer_Albedo的RGB通道是Albedo，A通道输入美术资源自带的AO</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/Snipaste_2023-08-22_04-27-39.jpg" style="zoom:20%;"></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/Snipaste_2023-08-22_04-27-57.jpg" style="zoom:20%;"></p><p>_GBuffer_Normal的RGB通道存储世界空间法线</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/Snipaste_2023-08-22_04-30-00.jpg" style="zoom:20%;"></p><p>_GBuffer_SpecularSmoothness的RGB通道存储金属的Specular，A通道存储光滑度</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/Snipaste_2023-08-22_04-30-01.jpg" style="zoom:20%;"></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/Snipaste_2023-08-22_04-31-50.jpg" style="zoom:20%;"></p><p>_GBuffer_GI 存储的是GI信息，动态物体的GI信息来自光照探针与反射探针，静态物体的GI信息来自光照贴图与反射探针。并且还会把主光源的实时阴影计算进去。（）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">float3 bakedGI;</span><br><span class="line">#if defined(DYNAMICLIGHTMAP_ON)</span><br><span class="line">bakedGI = SAMPLE_GI(input.staticLightmapUV, input.dynamicLightmapUV, input.vertexSH, normalWS);</span><br><span class="line">#else</span><br><span class="line">bakedGI = SAMPLE_GI(input.staticLightmapUV, input.vertexSH, normalWS);</span><br><span class="line">#endif</span><br><span class="line">Light mainLight = GetMainLight(input.shadowCoord, input.positionWS, shadowMask);</span><br><span class="line">MixRealtimeAndBakedGI(mainLight, normalWS, bakedGI, shadowMask);//使用shadowMask 混合 烘培阴影和实时阴影</span><br><span class="line">float occlusion = 1;</span><br><span class="line">float3 gi = GlobalIllumination(brdfData, bakedGI, occlusion, input.positionWS, normalWS, viewDirWS);</span><br><span class="line">//todo 加上自发光</span><br><span class="line">GB4 = half4(gi, 1);</span><br></pre></td></tr></table></figure><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/Snipaste_2023-08-22_04-34-16.jpg" style="zoom:20%;"></p><p>_GBuffer_ShadowMask 记录 shadowMask</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/Snipaste_2023-08-22_04-52-52.jpg" style="zoom:20%;"></p><p>_GDepth除了存储深度之后，还会存储模板值，GBuffer阶段输入不同材质的模板值，在光照计算阶段根据模板值渲染不同的结果。</p><h2 id="如何写入模板值"><a href="#如何写入模板值" class="headerlink" title="如何写入模板值"></a>如何写入模板值</h2><p>我们当然可以在shader中手动写入模板相关的操作，不过unity也提供了统一管理渲染状态的方法</p><p> context.DrawRenderers中可以传入一个自定义的SubShader中的Tag类型名 ，一组shaderTagId以及一组RenderStateBlock。</p><p>通过这种方式就可以让添加了这些shaderTagId的材质使用对应的RenderStateBlock。也就可以控制模板值如何写入</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ShaderTagId shaderTagKLMaterialType = new ShaderTagId(&quot;KLMaterialType&quot;);</span><br><span class="line"></span><br><span class="line">NativeArray&lt;ShaderTagId&gt; tagValues = new NativeArray&lt;ShaderTagId&gt;(shaderTagValues, Allocator.Temp);</span><br><span class="line">NativeArray&lt;RenderStateBlock&gt; stateBlocks = new NativeArray&lt;RenderStateBlock&gt;(renderStateBlocks, Allocator.Temp);</span><br><span class="line">               </span><br><span class="line">// KLMaterialTypeTag 为Tag 的名字</span><br><span class="line">context.DrawRenderers(cullingResults, ref drawSettings, ref filteringSettings, KLMaterialTypeTag, false, tagValues, stateBlocks);</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="草地渲染"><a href="#草地渲染" class="headerlink" title="草地渲染"></a>草地渲染</h1><p>《动物派对》中同样没有基于GPU Instancing的草地渲染，这也是我个人自己加上的，因为之前没写过，浅浅学习一下，看看存在哪些技术点。</p><h2 id="为什么不用unity的地形系统的植被功能？"><a href="#为什么不用unity的地形系统的植被功能？" class="headerlink" title="为什么不用unity的地形系统的植被功能？"></a>为什么不用unity的地形系统的植被功能？</h2><p>地形系统只能在Unity提供的mesh上进行植被的绘制，但是我希望草能长在我提供的mesh上</p><h2 id="unity提供的GPU-Instancing-方案如何使用，为什么不用？"><a href="#unity提供的GPU-Instancing-方案如何使用，为什么不用？" class="headerlink" title="unity提供的GPU Instancing 方案如何使用，为什么不用？"></a>unity提供的GPU Instancing 方案如何使用，为什么不用？</h2><p>默认管线中，只需要勾选 材质 中 的 “GPU Instancing ”，就可以开启GPU Instancing（默认管线没有SRP Batcher）</p><p>在URP管线中，如果材质 不支持SRP Btatcher 并且 勾选 材质 中 的 “GPU Instancing ”，就可以使用GPU Instancing</p><p>那么按照常理，在SRP中，只要我自己编写的 shader 支持 GPU Instancing ，不支持SRP Btatcher，是不是就可以直接使用GPU Instancing 了，那不就不用自己去实现一套草海绘制方案了吗？</p><p>其实并不是，unity官方文档表示，“<strong>Custom GPU instanced shaders</strong>”在SRP中是不支持的，只有在内置管线才支持（<a href="https://docs.unity3d.com/cn/current/Manual/gpu-instancing-shader.html）">https://docs.unity3d.com/cn/current/Manual/gpu-instancing-shader.html）</a></p><p>也就是说，我的材质不能直接享受GPU Instancing 的合批，所以想在srp中使用GPU Instancing ，只能调用 unity提供的API去自己实现了。</p><h2 id="选择哪个核心API？"><a href="#选择哪个核心API？" class="headerlink" title="选择哪个核心API？"></a>选择哪个核心API？</h2><p>unity提供了</p><p>Graphics.DrawMeshInstanced](<a href="https://docs.unity3d.com/cn/current/ScriptReference/Graphics.DrawMeshInstanced.html">https://docs.unity3d.com/cn/current/ScriptReference/Graphics.DrawMeshInstanced.html</a>)</p><p>与</p><p><a href="https://docs.unity3d.com/cn/current/ScriptReference/Rendering.CommandBuffer.DrawMeshInstanced.html">CommandBuffer.DrawMeshInstanced</a></p><p>两者的区别是什么？</p><p>文档中描述Graphics.DrawMeshInstanced，会把摄影机之外的实例进行剔除与排序（具体排序的限制一下没看懂），但是不会做遮挡剔除。也就是说不用担心视锥体之外的实例太多导致性能浪费。</p><p>CommandBuffer.DrawMeshInstanced 不会进行剔除，因为它是比较底层的，使用这个的时候需要考虑一下剔除的问题。</p><p>再考虑别的方面的区别。</p><p>Graphics 类的 优点是简单易用，无需创建 <code>CommandBuffer</code>，并且可以在不同的脚本中调用，缺点是不够灵活，无法在渲染过程中更精确地控制渲染命令的顺序和逻辑。难以实现高级的渲染效果。</p><p>CommandBuffer 的优缺点和Graphics 类相反。</p><p>关于Graphics.DrawMeshInstanced到底是如何起作用的猜测，我觉得这个函数最后应该还是会调用类似 CommandBuffer.DrawMeshInstanced的函数来把渲染命令增加到渲染队列中。 </p><p>分析到这里，在没有见过源码的情况下，结合demo现阶段的需求，我无法证明CommandBuffer.DrawMeshInstanced比 Graphics.DrawMeshInstanced好。</p><p>不过我还是选择CommandBuffer.DrawMeshInstanced，毕竟使用CommandBuffer还是比较有底。</p><p>使用CommandBuffer.DrawMeshInstanced，最核心的需求是。明确Mesh，Instance Material，以及一组坐标数据。</p><p>这些坐标数据需要以buffer或者贴图的形式直接传递给shader，在shader中利于instanceID 取采样到位置信息。</p><p>最大的需要解决的问题就是如何获取到坐标信息。</p><p>这次我的做法非常简单，我使用Prefab World Builder 作为我刷草的工具，把带有标记脚本的GameObject刷到场景中，来获取到一组坐标信息。需要说明的是，这绝对不是一个可商用的方式（我猜），我自己也没有对这套流程进行完善，只是为了能刷上草做的效果。随便学习unity中GPU Instancing  草的技术要点。</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/%E5%8A%A8%E7%94%BB1.gif" style="zoom:30%;"></p><h1 id="拷贝阴影图"><a href="#拷贝阴影图" class="headerlink" title="拷贝阴影图"></a>拷贝阴影图</h1><p>后续的Deferred shading中需要采样深度图，所以提前拷贝一份。</p><h1 id="HBAO-1"><a href="#HBAO-1" class="headerlink" title="HBAO"></a>HBAO</h1><p>HBAO的详细算法和原理解析在博客的其他文章中。贴一张效果演示。</p><p>在这里我把草地和场景的AO强度进行了区分。</p><p>原因是我觉得草地的AO效果强度需要比其他区域弱一些。、</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/Snipaste_2023-08-21_23-04-32.jpg" style="zoom:33%;"></p><h1 id="DeferredShading"><a href="#DeferredShading" class="headerlink" title="DeferredShading"></a>DeferredShading</h1><p>unity中使用了两种方式去渲染 分别是</p><p>RenderStencilLights 与 RenderTileLights</p><p>我暂时没有学会怎么写写RenderTileLights部分的代码，浅浅看了一下，应该是性能更优的做法。之后再研究一下。</p><p>这次的暂时先使用RenderStencilLights中的思路。</p><p>大致思路是，通过绘制光源形状的几何体确定光源作用范围，之后用模板值标记，然后在作用范围的像素中进行光照渲染。不过平行光不用做确定范围这一步，因为平行光对满屏都起作用。</p><p> DeferredShading pass中，传递完一些必要的数据之后，开始遍历每个有效灯光，每个灯光的循环中，传递灯光相关数据，并且绘制光源几何体，进行光照渲染。每种光照模型都需要单独的进行一次光照渲染，与之对应的是之前的GBuffer阶段输入了几种模板值，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">          for (int soffset = m_stencilVisLightOffsets[(int)LightType.Directional]; soffset &lt; m_stencilVisLights.Length; ++soffset)</span><br><span class="line">&#123;</span><br><span class="line">                ushort visLightIndex = m_stencilVisLights[soffset];</span><br><span class="line">                VisibleLight vl = visibleLights[visLightIndex];</span><br><span class="line">                if (vl.lightType != LightType.Directional)</span><br><span class="line">                    break;</span><br><span class="line">…………</span><br><span class="line">数据或者关键字相关的代码</span><br><span class="line">…………</span><br><span class="line">                // Lighting pass.</span><br><span class="line">                cmd.DrawMesh(m_FullscreenMesh, Matrix4x4.identity, m_StencilDeferredMaterial, 0, m_StencilDeferredPasses[(int)StencilDeferredPasses.DirectionalLit]);</span><br><span class="line">                cmd.DrawMesh(m_FullscreenMesh, Matrix4x4.identity, m_StencilDeferredMaterial, 0, m_StencilDeferredPasses[(int)StencilDeferredPasses.DirectionalSimpleLit]);</span><br><span class="line"></span><br><span class="line">                isFirstLight = false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="调色"><a href="#调色" class="headerlink" title="调色"></a>调色</h1><p>左为调色前，右为调色后</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/Snipaste_2023-08-22_09-41-30.jpg" alt></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/Snipaste_2023-08-24_06-33-04.jpg" alt></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/Snipaste_2023-08-22_09-43-23.jpg" alt></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/Snipaste_2023-08-24_06-32-42.jpg" alt></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>备忘录：Cook-Torrance公式推导与引擎代码位置</title>
      <link href="/2023/08/22/%E5%A4%87%E5%BF%98%E5%BD%95%EF%BC%9ACook-Torrance%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E4%B8%8E%E5%BC%95%E6%93%8E%E4%BB%A3%E7%A0%81%E4%BD%8D%E7%BD%AE/"/>
      <url>/2023/08/22/%E5%A4%87%E5%BF%98%E5%BD%95%EF%BC%9ACook-Torrance%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E4%B8%8E%E5%BC%95%E6%93%8E%E4%BB%A3%E7%A0%81%E4%BD%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>记录一些BRDF相关可能会需要回顾的知识</p><h1 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h1><h2 id="反射方程的解释"><a href="#反射方程的解释" class="headerlink" title="反射方程的解释"></a>反射方程的解释</h2><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/IMG_1459(20221028-145857" alt>.PNG)</p><h2 id="微表面理论"><a href="#微表面理论" class="headerlink" title="微表面理论"></a>微表面理论</h2><p><a href="https://www.yuque.com/xuegaojun-4mki0/vs4mcy/nx9f1i">https://www.yuque.com/xuegaojun-4mki0/vs4mcy/nx9f1i</a></p><h2 id="辐射度量学"><a href="#辐射度量学" class="headerlink" title="辐射度量学"></a>辐射度量学</h2><p><a href="https://www.yuque.com/xuegaojun-4mki0/vs4mcy/pdnuds">https://www.yuque.com/xuegaojun-4mki0/vs4mcy/pdnuds</a></p><h2 id="Cook-Torrance-BRDF"><a href="#Cook-Torrance-BRDF" class="headerlink" title="Cook-Torrance BRDF"></a>Cook-Torrance BRDF</h2><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/069119911cbe4ec5c531407bedd6f9d4491e3a2e30afaeea9280b0e117a802a5.png" alt></p><h2 id="Cook-Torrance漫反射部分公式"><a href="#Cook-Torrance漫反射部分公式" class="headerlink" title="Cook-Torrance漫反射部分公式"></a>Cook-Torrance漫反射部分公式</h2><p>漫反射部分设定，入射的irradiance和出射的radiance是一个固定的比例</p><p>即</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/Snipaste_2023-08-28_05-31-08.jpg" alt></p><h2 id="Cook-Torrance镜面反射部分公式推导"><a href="#Cook-Torrance镜面反射部分公式推导" class="headerlink" title="Cook-Torrance镜面反射部分公式推导"></a>Cook-Torrance镜面反射部分公式推导</h2><p>首先用公式表示某个方向的出射radiance。</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20221103212843.jpg" alt></p><p>这个出射方向上的辐射通量可以表示为：入射方向上接受到的辐射通量乘以菲涅尔项。</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20221103212849.jpg" alt></p><p>而入射方向上接受的辐射通量可以表示为如下公式</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20221103212855.jpg" alt></p><p>到此我们就可以表示出射方向上的radiance了，我们最终的目的是求解出射方向的radiance与从入射方向接收的irradiance的比例，所以有如下公式</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20221103212906.jpg" alt></p><p>求解两者的关系的方式我在网上找到三种，写在了语雀笔记中</p><p><a href="https://www.yuque.com/xuegaojun-4mki0/vs4mcy/rl3ubd">https://www.yuque.com/xuegaojun-4mki0/vs4mcy/rl3ubd</a></p><p>最终我们可以得到</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/06f724de7f77cbeaff50df608e8a648.jpg" alt></p><h1 id="工程方案相关"><a href="#工程方案相关" class="headerlink" title="工程方案相关"></a>工程方案相关</h1><p>在一些商业引擎中，会对公式进行一些改变。</p><p>例如BRDF = kd / pi + ks <em> (D </em> V * F) </p><p>其中V项定义为了可见性项（The Visibility Term）</p><p>untiy中的修改：BRDF = kD + kS <em> (D </em> V <em> F) </em> pi </p><h2 id="unity相关函数与代码位置"><a href="#unity相关函数与代码位置" class="headerlink" title="unity相关函数与代码位置"></a>unity相关函数与代码位置</h2><h3 id="InitializeBRDFData"><a href="#InitializeBRDFData" class="headerlink" title="InitializeBRDFData"></a>InitializeBRDFData</h3><p>定义BRDF数据，包括albedo，specular等等</p><p>位置：ShaderLibrary\BRDF.hlsl</p><h3 id="SAMPLE-GI"><a href="#SAMPLE-GI" class="headerlink" title="SAMPLE_GI"></a>SAMPLE_GI</h3><p>采样光照贴图或者解码球谐系数</p><p>位置：ShaderLibrary\GlobalIllumination.hlsl</p><h3 id="MixRealtimeAndBakedGI"><a href="#MixRealtimeAndBakedGI" class="headerlink" title="MixRealtimeAndBakedGI"></a>MixRealtimeAndBakedGI</h3><p>使用shadowMask 混合 烘培阴影和主光源实时阴影</p><p>位置：ShaderLibrary\GlobalIllumination.hlsl</p><h3 id="GlobalIllumination"><a href="#GlobalIllumination" class="headerlink" title="GlobalIllumination"></a>GlobalIllumination</h3><p>根据输入的brdf数据以及间接光漫反射，间接光镜面反射信息，计算全局光照的最终结果</p><p>位置：ShaderLibrary\GlobalIllumination.hlsl</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>还原View空间坐标的公式推导</title>
      <link href="/2023/08/15/%E8%BF%98%E5%8E%9FView%E7%A9%BA%E9%97%B4%E5%9D%90%E6%A0%87%E7%9A%84%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/"/>
      <url>/2023/08/15/%E8%BF%98%E5%8E%9FView%E7%A9%BA%E9%97%B4%E5%9D%90%E6%A0%87%E7%9A%84%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<p>从NDC空间还原view空间的公式推导</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20230821235528.jpg" alt></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20230821235534.jpg" alt></p><p>从结果可以看出，将NDC坐标乘于投影矩阵的逆矩阵止呕后，除以结果的w，就可以变回view空间坐标</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>PreZ与EarlyZ以及DephPass</title>
      <link href="/2023/08/14/PreZ%E4%B8%8EEarlyZ%E4%BB%A5%E5%8F%8AdephPass/"/>
      <url>/2023/08/14/PreZ%E4%B8%8EEarlyZ%E4%BB%A5%E5%8F%8AdephPass/</url>
      
        <content type="html"><![CDATA[<p>搭建渲染管线的时候，我们必须考虑深度相关的问题。</p><h1 id="为什么经常需要拷贝深度图？"><a href="#为什么经常需要拷贝深度图？" class="headerlink" title="为什么经常需要拷贝深度图？"></a>为什么经常需要拷贝深度图？</h1><p>为什么我们经常需要使用depth only pass 或者 copy depth pass 来复制一份深度图？</p><p>首先需要知道一个规则，unity中，当一个资源（比如纹理）被用作写入目标时，就不能在同一帧中直接对它进行采样。这应该是因为渲染的并行性质导致的内存的访问限制。</p><p>那么具体到实践中会有怎么样的限制呢？</p><p>以我自己搭建延迟渲染管线的时候遇到的情况举例。</p><p>当我在GBuffer将深度信息和模板信息写入名为”GDepth“的深度缓冲之后。</p><p>在渲染光照结果的阶段，我会需要GDepth作为我的深度缓冲。因为我需要旗帜的模板信息，同时我还需要采样深度信息，用于一些计算，例如还原世界坐标等等。这时候我就需要提前拷贝出一份深度缓冲。用于采样。</p><h1 id="PreZ和EarlyZ的关系什么？"><a href="#PreZ和EarlyZ的关系什么？" class="headerlink" title="PreZ和EarlyZ的关系什么？"></a>PreZ和EarlyZ的关系什么？</h1><p>在传统的渲染管线中，深度测试通常在片元着色阶段之后进行。也就是说，在片元着色器计算完成后，才会根据深度值来判断片元是否应该被渲染。然而，这样的方式可能会导致大量的片元着色计算，而其中很多片元最终由于深度测试失败被丢弃，造成了浪费。</p><p>Early Z（Early Depth Test）是图形渲染中的一种优化技术，用于在片元着色前尽早进行深度测试，以剔除不可见的片元，从而提高渲染性能。</p><p>Early Z 优化通过将深度测试提前到片元着色之前进行，可以在处理片元着色之前尽早判断出哪些片元是不可见的。当渲染器在遍历几何图元的过程中，对每个像素位置进行深度测试，如果发现当前像素的深度值在帧缓冲中已经有了一个更靠前的深度值，就可以知道该像素处于其他物体的后面，因此不需要继续进行片元着色计算，直接跳过这些片元，从而节省了大量的计算资源。</p><p>Early Z是基于硬件的优化机制，其限制是，如果我们在shader中开启了Alpha Clip，会让Early Z失效，</p><p>那么也就是说，我们只要不开启Alpha Clip，就可以一直享受Early Z的优化。那么类似树叶等等需要Alpha Clip的材质要怎么办呢？方法是，提前在一个pass中开启Alpha Clip把深度写入深度缓存。并且在正式渲染的pass中，把深度测试的方式设置为相等。我们就既可以正确渲染树叶，又可以享受Early Z的优化。</p><p>所以Pre Z 可以理解为一种优化手段。当然这不是绝对的，毕竟Pre Z也意味着多一次顶点shader计算。到底是否使用需要结合项目具体情况。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>备忘录：到底怎么调色啊！</title>
      <link href="/2023/08/13/%E5%88%B0%E5%BA%95%E6%80%8E%E4%B9%88%E8%B0%83%E8%89%B2%E5%95%8A/"/>
      <url>/2023/08/13/%E5%88%B0%E5%BA%95%E6%80%8E%E4%B9%88%E8%B0%83%E8%89%B2%E5%95%8A/</url>
      
        <content type="html"><![CDATA[<p>主要目的：学习常用的调色手段对画面的影响</p><h2 id="White-Balance-白平衡"><a href="#White-Balance-白平衡" class="headerlink" title="White Balance  白平衡"></a>White Balance  白平衡</h2><p>调整画面整体色调和色温，可以让画面偏冷一些或者偏暖一些。</p><p>unity中提供了两个参数分别控制色温和色调</p><div class="table-container"><table><thead><tr><th>Temperature</th><th>Set the white balance to a custom color temperature.</th></tr></thead><tbody><tr><td>Tint</td><td>Set the white balance to compensate for a green or magenta tint.</td></tr></tbody></table></div><h2 id="Channel-Mixer-通道混合"><a href="#Channel-Mixer-通道混合" class="headerlink" title="Channel Mixer  通道混合"></a>Channel Mixer  通道混合</h2><p>正常来说，RGB三个通道各自负责各种通道的颜色分量</p><p>也就是红色通道的值只会影响最终颜色的红色分量。</p><p>通道混合的作用就是，我可以改变三个通道对最终颜色的分量的影响。</p><p>举例来说，我可以让G通道的数值影响最终颜色的红色分量和蓝色分量。</p><p>原理很简单。那么从运用上来说，有什么一般性的方法吗？</p><p>有一些好用的规律</p><blockquote><p>红色的反面是青色</p><p>绿色的反面是洋红色</p><p>蓝色的反面是黄色</p></blockquote><p>例子：</p><p>1，如果我们想在画面的蓝色区域加洋红色，可以在绿色通道，把蓝色的贡献设置为负数。这样的话，画面在蓝色的部分就会给画面增加绿色的反面，也就是洋红色。</p><p>2，画面中有一片阳光的区域，偏红，我想让阳光偏向黄色。那么我可以选择蓝色通道，把红色的贡献调整为负值。</p><p>更多的规律以及更加复杂的技巧还是要靠经验来积累。</p><h2 id="Color-Adjustments-颜色调整"><a href="#Color-Adjustments-颜色调整" class="headerlink" title="Color Adjustments 颜色调整"></a>Color Adjustments 颜色调整</h2><p>通过<strong>颜色调整</strong>效果可调整最终渲染的图像的整体色调、亮度和对比度。</p><p><strong>Post Exposure </strong>调整曝光度</p><p><strong>Hue Shift </strong>调整对比度</p><p><strong>Saturation</strong> 调整饱和度</p><h2 id="Lift-Gamma-Gain"><a href="#Lift-Gamma-Gain" class="headerlink" title="Lift Gamma Gain"></a>Lift Gamma Gain</h2><p>Lift控制图像的暗部（阴影）区域的亮度水平</p><p>Gamma影响图像的中间色调（中间灰度）区域</p><p>Gain控制图像的亮部（高光）区域的亮度水平</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://docs.unity.cn/Packages/com.unity.postprocessing@3.1/manual/index.html">https://docs.unity.cn/Packages/com.unity.postprocessing@3.1/manual/index.html</a></p><p><a href="https://www.bilibili.com/video/BV1xr4y1s7a6/?spm_id_from=333.337.search-card.all.click&amp;vd_source=0fd5c7699dbf9665426cf07a40a03a04">https://www.bilibili.com/video/BV1xr4y1s7a6/?spm_id_from=333.337.search-card.all.click&amp;vd_source=0fd5c7699dbf9665426cf07a40a03a04</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>为何进行色调映射</title>
      <link href="/2023/08/12/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%9B%E8%A1%8C%E8%89%B2%E8%B0%83%E6%98%A0%E5%B0%84/"/>
      <url>/2023/08/12/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%9B%E8%A1%8C%E8%89%B2%E8%B0%83%E6%98%A0%E5%B0%84/</url>
      
        <content type="html"><![CDATA[<h1 id="HDR-的工作原理"><a href="#HDR-的工作原理" class="headerlink" title="HDR 的工作原理"></a>HDR 的工作原理</h1><p>在标准渲染中，像素的红色、绿色和蓝色值均使用一个 0 到 1 范围内的 8 位值进行存储，其中 0 表示零强度，1 表示显示设备的最大强度。这一有限的数值范围无法准确反映我们在现实生活中对光的感知方式，并且当存在非常亮或非常暗的元素时，会导致图像不真实。</p><p>在 HDR 渲染中，像素值使用浮点数进行存储。这种情况下允许更大范围的值，可以更准确地表示人眼感知颜色和亮度的方式。</p><h1 id="在unity中如何进行HDR渲染"><a href="#在unity中如何进行HDR渲染" class="headerlink" title="在unity中如何进行HDR渲染"></a>在unity中如何进行HDR渲染</h1><h1 id="为什么是HDR渲染-LDR输出"><a href="#为什么是HDR渲染-LDR输出" class="headerlink" title="为什么是HDR渲染+LDR输出"></a>为什么是HDR渲染+LDR输出</h1><p>既然HDR这么好，为什么很多时候我们还需要LDR输出？</p><p>原因是，显示设备的限制。</p><p>显示设备也需要接受数字信号去发光。也就是说这其中也有一个映射关系。如果显示器是所谓的LDR显示器，亮度范围小，支持的颜色深度也只有8bit。这时候我们把HDR信息传过去，也只会损失细节。</p><p>而目前的情况是市场上LDR显示器还是主流。所以一般来说我们都需要使用色调映射来把我们渲染出来的HDR信息映射到0到1的范围，利用色调映射的算法保留尽可能多的画面细节。然后再输出用于显示。</p><h1 id="色调映射（Tonemapping）"><a href="#色调映射（Tonemapping）" class="headerlink" title="色调映射（Tonemapping）"></a>色调映射（Tonemapping）</h1><blockquote><p>色调映射（Tonemapping）是数字图像处理中的一项技术，通常用于将高动态范围（HDR）图像转换为低动态范围（LDR）图像，以便在标准显示设备上显示或打印。HDR图像具有比常规LDR图像更大的亮度范围，可以捕捉到非常明亮和非常暗的细节。然而，由于大多数显示设备和打印机的限制，不能直接显示或输出这种广泛的亮度范围，因此需要使用色调映射技术来将HDR图像转换为适合显示的LDR版本。</p><p>色调映射的目标是在转换过程中保留尽可能多的图像细节，同时调整亮度和对比度，使图像在LDR范围内呈现出逼真的外观。这涉及到对图像中的亮度值进行映射和调整，以便在LDR范围内均匀分布亮度，避免高光和阴影区域的丢失细节或压缩。不同的色调映射算法采用不同的方法来实现这一目标，例如全局调整、局部对比度增强、曲线调整等。</p></blockquote><p>市面上的色调映射方案有很多种，在游戏制作的时候我们如何选择？</p><p>就ACES举例</p><p>ACES 分为Hill ACES 和 Narkowicz ACES。从运行效率上来说，前者比后者更消耗性能。</p><p>两者对于色调的映射的效果不一致。但是，未必费的方案就是更好的。</p><p>（虽然好像大家都说ACES是目前最好的色调映射方案）</p><p>个人目前认为，还是要在综合考虑的情况下基于美术的需求出发去选择方案</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://docs.unity.cn/cn/current/Manual/HDR.html">https://docs.unity.cn/cn/current/Manual/HDR.html</a></p><p><a href="https://www.youtube.com/watch?v=wbn5ULLtkHs">https://www.youtube.com/watch?v=wbn5ULLtkHs</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>HBAO从论文到工程</title>
      <link href="/2023/08/12/HBAO%E4%BB%8E%E8%AE%BA%E6%96%87%E5%88%B0%E5%B7%A5%E7%A8%8B/"/>
      <url>/2023/08/12/HBAO%E4%BB%8E%E8%AE%BA%E6%96%87%E5%88%B0%E5%B7%A5%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>我之前写在语雀上的HBAO实现笔记。</p><p>笔记链接：<a href="https://www.yuque.com/xuegaojun-4mki0/vs4mcy/xiagb9?singleDoc#">https://www.yuque.com/xuegaojun-4mki0/vs4mcy/xiagb9?singleDoc#</a></p><p>效果展示：</p><p>加AO前</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/HBAO1.jpg" alt></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/HBAO2.jpg" alt></p><p>加AO后</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/HBAO3.jpg" alt></p><h4 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h4><p><a href="http://artis.inrialpes.fr/Membres/Olivier.Hoel/ssao/nVidiaHSAO/2317-abstract.pdf">http://artis.inrialpes.fr/Membres/Olivier.Hoel/ssao/nVidiaHSAO/2317-abstract.pdf</a></p><p><a href="https://github.com/scanberg/hbao/blob/master/resources/shaders/hbao_frag.glsl">https://github.com/scanberg/hbao/blob/master/resources/shaders/hbao_frag.glsl</a></p><p> <a href="https://zhuanlan.zhihu.com/p/545497019">https://zhuanlan.zhihu.com/p/545497019</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>透视插值修正</title>
      <link href="/2023/08/07/%E9%80%8F%E8%A7%86%E6%8F%92%E5%80%BC%E4%BF%AE%E6%AD%A3/"/>
      <url>/2023/08/07/%E9%80%8F%E8%A7%86%E6%8F%92%E5%80%BC%E4%BF%AE%E6%AD%A3/</url>
      
        <content type="html"><![CDATA[<p>属性插值的透视修正，图像API和硬件层面已经处理了。</p><p>不过出于学习的目的还是可以研究一下。</p><p>顶点属性的插值发生在光栅化阶段</p><p>插值基于重心坐标。</p><p>而计算重心坐标，需要知道顶点坐标，关键在于，是什么空间下的顶点坐标？</p><p>如果是已屏幕空间坐标计算重心坐标，由于透视投影，插值会出问题。我们更想要计算的透视投影之前，3D空间中对应点的重心坐标。</p><p>但是如果这样，就需要求出3d空间的重心坐标，直觉上来讲，我们还需要还原这个点在3D空间中的坐标，然后再根据空间中的三个顶点坐标对P点的属性进行插值。这很麻烦。</p><p>如果我们能直接求到投影之前的3D空间的重心坐标，就可以直接进行属性插值了。</p><p>三角形从view 空间 ，经过投影矩阵变换，再进行透视除法，转移到NDC空间。在映射到Screen空间</p><p>view空间到NDC空间，进行了顶点相对位置产生变化，重心坐标发生了变化。</p><p>NDC空间到Screen空间。只是进行了缩放，重心坐标没有发生变化。</p><p>也就是说，我们只要找到view空间和NDC空间中重心坐标的映射关系，就可以解决插值问题。</p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/1.jpg" alt></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/2.jpg" alt></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/3.jpg" alt></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/4.jpg" alt></p><p><img src="https://ykl1998.oss-cn-hangzhou.aliyuncs.com/img/%E9%A1%B6%E7%82%B9%E8%89%B2%E4%B8%BA%E4%BE%8B.jpg" alt></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>URP延迟渲染</title>
      <link href="/2023/08/04/URP%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93/"/>
      <url>/2023/08/04/URP%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93/</url>
      
        <content type="html"><![CDATA[<h1 id="URP的GBuffer布局"><a href="#URP的GBuffer布局" class="headerlink" title="URP的GBuffer布局"></a>URP的GBuffer布局</h1><p><img src="data-structure-render-targets-g-buffer.png" alt></p><blockquote><p>该数据结构包含以下组件。</p><p><strong>Albedo (sRGB)</strong></p><p>此字段包含 sRGB 格式的反照率颜色（24 位）。</p><p><strong>MaterialFlags</strong></p><p>此字段是包含材质标志的位字段：</p><ul><li>位 1 - <strong>ReceiveShadowsOff</strong>：如果设置此位，像素不会接收动态阴影。</li><li>位 2 - <strong>SpecularHighlightsOff</strong>：如果设置此位，像素不会接收镜面高光。</li><li>位 4 - <strong>SubtractiveMixedLighting</strong>：如果设置此位，像素将使用减法混合光照。</li><li>位 8 - <strong>SpecularSetup</strong>：如果设置此位，材质将使用镜面反射工作流程。</li></ul><p>如需了解更多技术细节，请参阅 <code>/ShaderLibrary/UnityGBuffer.hlsl</code> 文件。</p><p><strong>Specular</strong></p><p>此字段包含以下值：</p><ul><li>SimpleLit Material：以 24 位存储的 RGB 镜面反射颜色。</li><li>Lit Material with metallic workflow：以 8 位存储反射率，不使用 16 位。</li><li>Lit Material with specular workflow：以 24 位存储的 RGB 镜面反射颜色。</li></ul><p><strong>Occlusion</strong></p><p>此字段包含来自烘焙光照的烘焙遮挡值。对于实时光照，Unity 通过将烘焙遮挡值与 SSAO 值结合来计算环境光遮挡值。</p><p><strong>Normal</strong></p><p>此字段包含以 24 位编码的世界空间法线。有关法线编码的信息，请参阅 <a href="https://docs.unity3d.com/cn/Packages/com.unity.render-pipelines.universal@12.1/manual/rendering/deferred-rendering-path.html#accurate-g-buffer-normals">G 缓冲区中的法线编码</a>一节。</p><p><strong>Smoothness</strong></p><p>此字段存储 SimpleLit 和 Lit 材质的平滑度值。</p><p><strong>Emissive/GI/Lighting</strong></p><p>此渲染目标包含材质发光输出和烘焙光照。Unity 在 G 缓冲区通道期间填充这一字段。在延迟着色通道期间，Unity 将光照结果存储在此渲染目标中。</p><p>渲染目标格式：</p><ul><li><strong>B10G11R11_UFloatPack32</strong>，除非以下条件之一成立：<ul><li>在 URP 资源中，已开启 <strong>Quality</strong> &gt; <strong>HDR</strong> 设置，并且目标 Player 平台不支持 HDR。</li><li>在 Player Settings 中，<strong>PreserveFramebufferAlpha</strong> 设置为 true。</li></ul></li><li><strong>R16G6B16A16_SFloat</strong>（如果 Unity 由于项目设置而无法使用 <strong>B10G11R11_UFloatPack32</strong>）。</li><li>如果 Unity 无法使用列表中的其他格式之一，它将使用以下方法的返回结果：<code>SystemInfo.GetGraphicsFormat(DefaultFormat.HDR)</code>。</li></ul><p><strong>ShadowMask</strong></p><p>当 Lighting Mode 设置为 Subtractive 或 Shadow mask 时，Unity 会将此渲染目标添加到 G 缓冲区布局。</p><p>Subtractive 和 Shadow mask 模式针对前向渲染路径进行了优化，但在延迟渲染路径中的效率较低。在延迟渲染路径中，应避免使用这些模式，而是使用 Baked Indirect 模式来提高 GPU 性能。</p><p><strong>Rendering Layer Mask</strong></p><p>当光源层 (Light Layers) 功能已启用（在 URP 资源中选择 <strong>Advanced</strong> &gt; <strong>Light Layers</strong>）时，Unity 会将此渲染目标添加到 G 缓冲区布局。光源层功能可能会对 GPU 性能产生重大影响。有关更多信息，请参阅<a href="https://docs.unity3d.com/cn/Packages/com.unity.render-pipelines.universal@12.1/manual/rendering/deferred-rendering-path.html#light-layers">光源层</a>。</p><p><strong>Depth as Color</strong></p><p>在支持的平台上启用原生渲染通道 (Native Render Pass) 时，Unity 会将此渲染目标添加到 G 缓冲区布局。Unity 会将深度作为颜色渲染到此渲染目标中。此渲染目标具有以下用途：</p><ul><li>在 Vulkan 设备上提高性能。</li><li>让 Unity 在 Metal API 上获取深度缓冲区，这不允许在同一渲染通道内从 DepthStencil 缓冲区获取深度。</li></ul><p>Depth as Color 渲染目标的格式是 <code>GraphicsFormat.R32_SFloat</code>。</p><p><strong>DepthStencil</strong></p><p>Unity 保留此渲染目标的四个最高位来标记材质类型。另请参阅 <a href="https://docs.unity3d.com/cn/Packages/com.unity.render-pipelines.universal@12.1/manual/urp-shaders/urp-shaderlab-pass-tags.html#universalmaterialtype">URP Pass 标签：UniversalMaterialType</a>。</p><p>对于此渲染目标，Unity 根据平台选择 <code>D32F_S8</code> 格式或 <code>D24S8</code> 格式。</p><p><strong>当摄像机使用 HDR 渲染时，不会为发射 + 光照缓冲区 (RT3) 创建单独的渲染目标；而是将摄像机渲染到的渲染目标（即传递给图像效果的渲染目标）用作 RT3。</strong></p></blockquote><p>MaterialFlags的部分，位4 指的是  materialFlags |= 4;</p><h2 id="Emissive-GI-Lighting部分："><a href="#Emissive-GI-Lighting部分：" class="headerlink" title="Emissive/GI/Lighting部分："></a><strong>Emissive/GI/Lighting</strong>部分：</h2><p>这部分到底存储了怎么样的信息？</p><p>下面是部分代码</p><figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//LitGBufferPass.hlsl</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//  InitializeInputData部分：这里得到的bakedGI，可能是从lightMap得到的也可能是光照探针（SH）中得到的</span></span><br><span class="line"> InputData inputData;</span><br><span class="line">    InitializeInputData(unpacked, surfaceDescription, inputData);</span><br><span class="line">BRDFData brdfData;</span><br><span class="line"></span><br><span class="line">    InitializeBRDFData(surfaceData.albedo, surfaceData.metallic, surfaceData.specular, surfaceData.smoothness, surfaceData.alpha, brdfData);</span><br><span class="line"></span><br><span class="line">    Light mainLight = GetMainLight(inputData.shadowCoord, inputData.positionWS, inputData.shadowMask);</span><br><span class="line"><span class="comment">//MixRealtimeAndBakedGI:如果使用了LightMap，并且 使用Subtractive 模式。则按照SubtractDirectMainLightFromLightmap中的方法进行烘培GI混合。</span></span><br><span class="line">    MixRealtimeAndBakedGI(mainLight, inputData.normalWS, inputData.bakedGI, inputData.shadowMask);</span><br><span class="line"><span class="comment">//GlobalIllumination：混合间接光 和 主光源 的直接光</span></span><br><span class="line">half3 color = GlobalIllumination(brdfData, inputData.bakedGI, surfaceData.occlusion, inputData.positionWS, inputData.normalWS, inputData.viewDirectionWS);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> BRDFDataToGbuffer(brdfData, inputData, surfaceData.smoothness, surfaceData.emission + color, surfaceData.occlusion);</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">void MixRealtimeAndBakedGI(inout Light light, half3 normalWS, inout half3 bakedGI)</span><br><span class="line">&#123;</span><br><span class="line">#if defined(LIGHTMAP_ON) &amp;&amp; defined(_MIXED_LIGHTING_SUBTRACTIVE)</span><br><span class="line">    bakedGI = SubtractDirectMainLightFromLightmap(light, normalWS, bakedGI);</span><br><span class="line">#endif</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Backwards compatibility</span><br><span class="line">void MixRealtimeAndBakedGI(inout Light light, half3 normalWS, inout half3 bakedGI, half4 shadowMask)</span><br><span class="line">&#123;</span><br><span class="line">    MixRealtimeAndBakedGI(light, normalWS, bakedGI);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">half3 SubtractDirectMainLightFromLightmap(Light mainLight, half3 normalWS, half3 bakedGI)</span><br><span class="line">&#123;</span><br><span class="line">    // Let&#x27;s try to make realtime shadows work on a surface, which already contains</span><br><span class="line">    // baked lighting and shadowing from the main sun light.</span><br><span class="line">    // Summary:</span><br><span class="line">    // 1) Calculate possible value in the shadow by subtracting estimated light contribution from the places occluded by realtime shadow:</span><br><span class="line">    //      a) preserves other baked lights and light bounces</span><br><span class="line">    //      b) eliminates shadows on the geometry facing away from the light</span><br><span class="line">    // 2) Clamp against user defined ShadowColor.</span><br><span class="line">    // 3) Pick original lightmap value, if it is the darkest one.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    // 1) Gives good estimate of illumination as if light would&#x27;ve been shadowed during the bake.</span><br><span class="line">    // We only subtract the main direction light. This is accounted in the contribution term below.</span><br><span class="line">    half shadowStrength = GetMainLightShadowStrength();</span><br><span class="line">    half contributionTerm = saturate(dot(mainLight.direction, normalWS));</span><br><span class="line">    half3 lambert = mainLight.color * contributionTerm;</span><br><span class="line">    half3 estimatedLightContributionMaskedByInverseOfShadow = lambert * (1.0 - mainLight.shadowAttenuation);</span><br><span class="line">    half3 subtractedLightmap = bakedGI - estimatedLightContributionMaskedByInverseOfShadow;</span><br><span class="line"></span><br><span class="line">    // 2) Allows user to define overall ambient of the scene and control situation when realtime shadow becomes too dark.</span><br><span class="line">    half3 realtimeShadow = max(subtractedLightmap, _SubtractiveShadowColor.xyz);</span><br><span class="line">    realtimeShadow = lerp(bakedGI, realtimeShadow, shadowStrength);</span><br><span class="line"></span><br><span class="line">    // 3) Pick darkest color</span><br><span class="line">    return min(bakedGI, realtimeShadow);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">half3 GlobalIllumination(BRDFData brdfData, BRDFData brdfDataClearCoat, float clearCoatMask,</span><br><span class="line">    half3 bakedGI, half occlusion, float3 positionWS,</span><br><span class="line">    half3 normalWS, half3 viewDirectionWS)</span><br><span class="line">&#123;</span><br><span class="line">    half3 reflectVector = reflect(-viewDirectionWS, normalWS);</span><br><span class="line">    half NoV = saturate(dot(normalWS, viewDirectionWS));</span><br><span class="line">    half fresnelTerm = Pow4(1.0 - NoV);</span><br><span class="line"></span><br><span class="line">    half3 indirectDiffuse = bakedGI;</span><br><span class="line">    half3 indirectSpecular = GlossyEnvironmentReflection(reflectVector, positionWS, brdfData.perceptualRoughness, 1.0h);</span><br><span class="line"></span><br><span class="line">    half3 color = EnvironmentBRDF(brdfData, indirectDiffuse, indirectSpecular, fresnelTerm);</span><br><span class="line"></span><br><span class="line">    if (IsOnlyAOLightingFeatureEnabled())</span><br><span class="line">    &#123;</span><br><span class="line">        color = half3(1,1,1); // &quot;Base white&quot; for AO debug lighting mode</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">#if defined(_CLEARCOAT) || defined(_CLEARCOATMAP)</span><br><span class="line">    half3 coatIndirectSpecular = GlossyEnvironmentReflection(reflectVector, positionWS, brdfDataClearCoat.perceptualRoughness, 1.0h);</span><br><span class="line">    // TODO: &quot;grazing term&quot; causes problems on full roughness</span><br><span class="line">    half3 coatColor = EnvironmentBRDFClearCoat(brdfDataClearCoat, clearCoatMask, coatIndirectSpecular, fresnelTerm);</span><br><span class="line"></span><br><span class="line">    // Blend with base layer using khronos glTF recommended way using NoV</span><br><span class="line">    // Smooth surface &amp; &quot;ambiguous&quot; lighting</span><br><span class="line">    // NOTE: fresnelTerm (above) is pow4 instead of pow5, but should be ok as blend weight.</span><br><span class="line">    half coatFresnel = kDielectricSpec.x + kDielectricSpec.a * fresnelTerm;</span><br><span class="line">    return (color * (1.0 - coatFresnel * clearCoatMask) + coatColor) * occlusion;</span><br><span class="line">#else</span><br><span class="line">    return color * occlusion;</span><br><span class="line">#endif</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Backwards compatiblity</span><br><span class="line">half3 GlobalIllumination(BRDFData brdfData, half3 bakedGI, half occlusion, float3 positionWS, half3 normalWS, half3 viewDirectionWS)</span><br><span class="line">&#123;</span><br><span class="line">    const BRDFData noClearCoat = (BRDFData)0;</span><br><span class="line">    return GlobalIllumination(brdfData, noClearCoat, 0.0, bakedGI, occlusion, positionWS, normalWS, viewDirectionWS);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从结果看，Emissive/GI/Lighting 存储的就是烘培GI（LightMap 或者 SH）经过PBR公式计算之后输出的radiance。额外加上了自发光的radiance</p><p>另外，如果进行了光照烘培，并且使用了Subtractive模式，还会进行烘培阴影和实时阴影的混合。</p><h3 id="Subtractive-模式下的GI混合"><a href="#Subtractive-模式下的GI混合" class="headerlink" title="Subtractive 模式下的GI混合"></a>Subtractive 模式下的GI混合</h3><p>Subtractive下的光照混合是个值得了解的事情。</p><p>Subtractive模式下，对于Mixed模式下的主光源来说，静态物体的直接光和间接光以及阴影都已经烘培到LightMap上，并且动态物体仍然受到实时光影响，动态物体的影子还是会投射到静态物体上。这个时候，就难免出现一种情况：一个静态物体既受到实时阴影，又有自身的烘培阴影。我们需要将两者进行混合。</p><p>代码如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">half3 SubtractDirectMainLightFromLightmap(Light mainLight, half3 normalWS, half3 bakedGI)</span><br><span class="line">&#123;</span><br><span class="line">    // Let&#x27;s try to make realtime shadows work on a surface, which already contains</span><br><span class="line">    // baked lighting and shadowing from the main sun light.</span><br><span class="line">    // Summary:</span><br><span class="line">    // 1) Calculate possible value in the shadow by subtracting estimated light contribution from the places occluded by realtime shadow:</span><br><span class="line">    //      a) preserves other baked lights and light bounces</span><br><span class="line">    //      b) eliminates shadows on the geometry facing away from the light</span><br><span class="line">    // 2) Clamp against user defined ShadowColor.</span><br><span class="line">    // 3) Pick original lightmap value, if it is the darkest one.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    // 1) Gives good estimate of illumination as if light would&#x27;ve been shadowed during the bake.</span><br><span class="line">    // We only subtract the main direction light. This is accounted in the contribution term below.</span><br><span class="line">    half shadowStrength = GetMainLightShadowStrength();</span><br><span class="line">    half contributionTerm = saturate(dot(mainLight.direction, normalWS));</span><br><span class="line">    half3 lambert = mainLight.color * contributionTerm;</span><br><span class="line">    half3 estimatedLightContributionMaskedByInverseOfShadow = lambert * (1.0 - mainLight.shadowAttenuation);</span><br><span class="line">    half3 subtractedLightmap = bakedGI - estimatedLightContributionMaskedByInverseOfShadow;</span><br><span class="line"></span><br><span class="line">    // 2) Allows user to define overall ambient of the scene and control situation when realtime shadow becomes too dark.</span><br><span class="line">    half3 realtimeShadow = max(subtractedLightmap, _SubtractiveShadowColor.xyz);</span><br><span class="line">    realtimeShadow = lerp(bakedGI, realtimeShadow, shadowStrength);</span><br><span class="line"></span><br><span class="line">    // 3) Pick darkest color</span><br><span class="line">    return min(bakedGI, realtimeShadow);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实时阴影的颜色计算基于BakedGI， 在 自定义的阴影颜色 和 subtractedLightmap 中取大值</p><p>并且实时阴影的颜色 可以用强度值 控制</p><p>得到了实时阴影之后，在实时阴影和烘培结果 中取最小值。</p><p>我们可以通过调整实时阴影颜色让混合结果尽可能的自然。</p><h1 id="Rendering"><a href="#Rendering" class="headerlink" title="Rendering"></a>Rendering</h1><h2 id="标记光照模型类型"><a href="#标记光照模型类型" class="headerlink" title="标记光照模型类型"></a>标记光照模型类型</h2><p>unity在GBuffer阶段 会给不同的光照模型设置不同的模板值。</p><p>urp的GBuffer Pass 中，使用了 RenderStateBlock 列表和 tag列表 来控制不同光照模型的渲染状态(主要是设置模板测试)，而不是在shader的GBuffer pass 中设置渲染状态。</p><p>而且urp中自定义了一个新的tag类型叫做“UniversalMaterialType”，这个tag在标记光照模型的模板值的时候被使用。</p><h2 id="标记受光影响像素"><a href="#标记受光影响像素" class="headerlink" title="标记受光影响像素"></a>标记受光影响像素</h2><p>所有的光源都会渲染为几何体，例如，点光源为球体，聚光灯为锥体等。只有在几何体内部的像素才会受到光源影响。使用模板测试来实现。</p><p>每一盏灯光，都会 遍历 所有 准备在延迟渲染中渲染结果的光照模型。计算光照结果。如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> //urp的延迟渲染中，lit和simpleLit两种光照模型会在延迟渲染中被渲染结果。</span><br><span class="line"> //每一盏灯光都会分别为这两种光照模型去渲染一次光源几何体。</span><br><span class="line">cmd.DrawMesh(m_FullscreenMesh, Matrix4x4.identity, m_StencilDeferredMaterial, 0, m_StencilDeferredPasses[(int)StencilDeferredPasses.DirectionalLit]);</span><br><span class="line">cmd.DrawMesh(m_FullscreenMesh, Matrix4x4.identity, m_StencilDeferredMaterial, 0, m_StencilDeferredPasses[(int)StencilDeferredPasses.DirectionalSimpleLit]);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>平行光的影响范围包含整个屏幕，点光源和聚光灯则有一定的作用范围。所以这两种光源渲染结果之前需要确定作用范围，也就是哪些像素被光照亮了。</p><p>如何确定像素是在光源几何体之内？</p><p>画了个草图，可以看出，只要场景深度大于光源几何体正面深度，小于光源几何体背面深度，就可以确定是在光源范围之内。</p><p><img src="3.jpg" alt></p><p>回到unity中，点光源和聚光灯会先执行Stencil Volume Pass，这个Pass设定 几何体 剔除背面，Ztest 规则为小于等于，如果有像素的深度测试没有通过，则会将模板值的第5位求反。场景默认模板值为0，Lit和sampleLit两种光照模型的物体分别写入了模板值0010 0000和0100 0000，也就是第6和第7位。反转第5位之后，第5位为1.</p><p>之后，只要检测像素满足以下两个条件：1，光源几何体 背面深度大于场景深度。2，像素模板值中，第5位为1（表示像素受光照影响），光照模型对应的位也为1（表示当前像素使用的是当前pass的光照模型）<br>符合条件之后，则会进行光照渲染，并且把模板值第5位归0（下一个灯光渲染的时候会重新计算）</p><h2 id="使用GBuffer-计算光照结果"><a href="#使用GBuffer-计算光照结果" class="headerlink" title="使用GBuffer 计算光照结果"></a>使用GBuffer 计算光照结果</h2><p>参考  StencilDeferred.shader</p><p>首先如果当前像素渲染的物体和灯光都是static的，那么就没有实时光结果需要渲染</p><h2 id="ShadowMask-模式下-ShadowMask-GBuffer的使用"><a href="#ShadowMask-模式下-ShadowMask-GBuffer的使用" class="headerlink" title="ShadowMask 模式下 ShadowMask GBuffer的使用"></a>ShadowMask 模式下 ShadowMask GBuffer的使用</h2><figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">half <span class="title">MainLightShadow</span>(<span class="params">float4 shadowCoord, float3 positionWS, half4 shadowMask, half4 occlusionProbeChannels</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    half realtimeShadow = MainLightRealtimeShadow(shadowCoord);</span><br><span class="line"></span><br><span class="line"><span class="meta">#ifdef CALCULATE_BAKED_SHADOWS</span></span><br><span class="line">    half bakedShadow = BakedShadow(shadowMask, occlusionProbeChannels);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    half bakedShadow = half(<span class="number">1.0</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#ifdef MAIN_LIGHT_CALCULATE_SHADOWS</span></span><br><span class="line">    half shadowFade = GetMainLightShadowFade(positionWS);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span>//如果主光源不投射阴影，最后的结果就完全是 bakedShadow</span></span><br><span class="line">    half shadowFade = half(<span class="number">1.0</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MixRealtimeAndBakedShadows(realtimeShadow, bakedShadow, shadowFade);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">half <span class="title">BakedShadow</span>(<span class="params">half4 shadowMask, half4 occlusionProbeChannels</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// Here occlusionProbeChannels used as mask selector to select shadows in shadowMask</span></span><br><span class="line">    <span class="comment">// If occlusionProbeChannels all components are zero we use default baked shadow value 1.0</span></span><br><span class="line">    <span class="comment">// This code is optimized for mobile platforms:</span></span><br><span class="line">    <span class="comment">// half bakedShadow = any(occlusionProbeChannels) ? dot(shadowMask, occlusionProbeChannels) : 1.0h;</span></span><br><span class="line">    half bakedShadow = half(<span class="number">1.0</span>) + dot(shadowMask - half(<span class="number">1.0</span>), occlusionProbeChannels);</span><br><span class="line">    <span class="keyword">return</span> bakedShadow;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//表示基于像素与摄像机之间的距离的阴影淡出效果。</span></span><br><span class="line"><span class="comment">//当像素距离摄像机越远时，这个淡出效果会更明显，导致远离摄像机的像素的阴影变得更淡。这可以用来模拟现实世界中，远离观察者的物体的阴影边缘变得更模糊的效果。</span></span><br><span class="line"><span class="function">half <span class="title">GetMainLightShadowFade</span>(<span class="params">float3 positionWS</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    float3 camToPixel = positionWS - _WorldSpaceCameraPos;</span><br><span class="line">    <span class="built_in">float</span> distanceCamToPixel2 = dot(camToPixel, camToPixel);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">float</span> fade = saturate(distanceCamToPixel2 * <span class="built_in">float</span>(_MainLightShadowParams.z) + <span class="built_in">float</span>(_MainLightShadowParams.w));</span><br><span class="line">    <span class="keyword">return</span> half(fade);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">half <span class="title">MixRealtimeAndBakedShadows</span>(<span class="params">half realtimeShadow, half bakedShadow, half shadowFade</span>)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(LIGHTMAP_SHADOW_MIXING)//如果使用了混合阴影，则在bakedShadow和realtimeShadow中取最小值</span></span><br><span class="line">    <span class="keyword">return</span> min(lerp(realtimeShadow, <span class="number">1</span>, shadowFade), bakedShadow);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="keyword">return</span> lerp(realtimeShadow, bakedShadow, shadowFade);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function">half <span class="title">GetMainLightShadowFade</span>(<span class="params">float3 positionWS</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    float3 camToPixel = positionWS - _WorldSpaceCameraPos;</span><br><span class="line">    <span class="built_in">float</span> distanceCamToPixel2 = dot(camToPixel, camToPixel);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">float</span> fade = saturate(distanceCamToPixel2 * <span class="built_in">float</span>(_MainLightShadowParams.z) + <span class="built_in">float</span>(_MainLightShadowParams.w));</span><br><span class="line">    <span class="keyword">return</span> half(fade);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="TODO-URP-Lit-与-sample-Lit-的区别"><a href="#TODO-URP-Lit-与-sample-Lit-的区别" class="headerlink" title="TODO URP Lit 与 sample Lit 的区别"></a>TODO URP Lit 与 sample Lit 的区别</h2><h1 id="相关代码文件"><a href="#相关代码文件" class="headerlink" title="相关代码文件"></a>相关代码文件</h1><ul><li><p>负责处理延迟渲染路径的主类：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">com.unity.render-pipelines.universal\Runtime\DeferredLights.cs</span><br></pre></td></tr></table></figure></li><li><p>G 缓冲区通道的 ScriptableRenderPass：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">com.unity.render-pipelines.universal\Runtime\Passes\GBufferPass.cs</span><br></pre></td></tr></table></figure></li><li><p>延迟着色通道的 ScriptableRenderPass：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">com.unity.render-pipelines.universal\Runtime\Passes\DeferredPass.cs</span><br></pre></td></tr></table></figure></li><li><p>用于延迟着色的着色器资源：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">com.unity.render-pipelines.universal\Shaders\Utils\StencilDeferred.shader</span><br></pre></td></tr></table></figure></li><li><p>延迟着色的实用函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">com.unity.render-pipelines.universal\Shaders\Utils\Deferred.hlsl</span><br></pre></td></tr></table></figure></li><li><p>用于存储以及从 G 缓冲区加载材质属性的实用函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">com.unity.render-pipelines.universal\Shaders\Utils\UnityGBuffer.hlsl</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>备忘录：DXBC逆向</title>
      <link href="/2023/07/21/DXBC%E9%80%86%E5%90%91%E8%A7%A3%E8%AF%BB/"/>
      <url>/2023/07/21/DXBC%E9%80%86%E5%90%91%E8%A7%A3%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h2 id="mov"><a href="#mov" class="headerlink" title="mov"></a>mov</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mov r0.xyz v2.xyzx</span><br><span class="line">//该指令等价于r0.xyz = v2;</span><br></pre></td></tr></table></figure><h2 id="add"><a href="#add" class="headerlink" title="add"></a>add</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add r3.xyz, r3.xyzx, r1.xyzx，该指令等价于r3.xyz += r1.xyz;</span><br></pre></td></tr></table></figure><h2 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sample_indexable r2.xyzw, v4.xyxx, t0.xyzw, s0，</span><br><span class="line">该指令等价于：r2 = tex2D(t0, v4.xy);</span><br></pre></td></tr></table></figure><h2 id="mul"><a href="#mul" class="headerlink" title="mul"></a>mul</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mul r0.xyz r1.xyz r2.xyz，该指令等价于r0.xyz = r1.xyz * r2.xyz;</span><br></pre></td></tr></table></figure><h2 id="rsq"><a href="#rsq" class="headerlink" title="rsq"></a>rsq</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsq r1.w, r1.w，等价于r1.w = rsqrt(r1.w); 是倒数的平方根</span><br></pre></td></tr></table></figure><h2 id="max"><a href="#max" class="headerlink" title="max"></a>max</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">max r1.x, r1.x, r1.y，等价于r1.x = max(r1.x, r1.y);</span><br></pre></td></tr></table></figure><h2 id="div"><a href="#div" class="headerlink" title="div"></a>div</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iv r8.xyzw, l(1.000000, 1.000000, 1.000000, 1.000000), r8.xyzw，等价于 r8 = r8 / 1.;</span><br></pre></td></tr></table></figure><h2 id="mad"><a href="#mad" class="headerlink" title="mad"></a>mad</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mad dst， src0， src1， src2</span><br><span class="line">=&gt;</span><br><span class="line">dest.x = src0.x * src1.x + src2.x;</span><br></pre></td></tr></table></figure><h2 id="movc"><a href="#movc" class="headerlink" title="movc"></a>movc</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">movc o0.xyzw,r0.xxxx,l(0,0,0,0),l(1.000000,1.000000,1.000000,1.000000)</span><br><span class="line">// r0.xxxx不为0，就用l(0,0,0,0)，否者就用l(1.000000,1.000000,1.000000,1.000000)</span><br></pre></td></tr></table></figure><h2 id="寄存器的重复使用"><a href="#寄存器的重复使用" class="headerlink" title="寄存器的重复使用"></a>寄存器的重复使用</h2><p>DXBC会重复使用变量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//表示此段shader需要19个临时变量，从r0开始到r18</span><br><span class="line">dcl_temps 19</span><br></pre></td></tr></table></figure><h2 id="通道补全"><a href="#通道补全" class="headerlink" title="通道补全"></a>通道补全</h2><p>DXBC中，向量的计算只有单通道或者四通道。超过单通道或者不满四通道的向量会自动补全为四通道。</p><p>比如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mad r3.yzw, r0.zzzz, r4.xxyz, r2.yyzw</span><br><span class="line">=&gt;</span><br><span class="line">r3.yzw = r0.z * r4.xyz + r2.yzw;</span><br></pre></td></tr></table></figure><h2 id="abs"><a href="#abs" class="headerlink" title="abs()"></a>abs()</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">max r4.w, abs(r4.w), l(0.0000) </span><br><span class="line">=&gt;</span><br><span class="line">r4.w = max(abs(r4.w) ,0.000) </span><br></pre></td></tr></table></figure><h2 id="saturate"><a href="#saturate" class="headerlink" title="saturate()"></a>saturate()</h2><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mad_sat r5.w, r5.w, cb4[<span class="number">154</span>].y, r6.w</span><br><span class="line">=&gt;</span><br><span class="line">r5.w = saturate(r5.w * cb4[<span class="number">154</span>].y + r6.w)</span><br><span class="line"></span><br><span class="line">div_sat r5.w, r5.w, cb4[<span class="number">160</span>].w</span><br><span class="line">=&gt;</span><br><span class="line">r5.w =  saturate( r5.w /  cb4[<span class="number">160</span>].w )</span><br></pre></td></tr></table></figure><h2 id="smoothstep"><a href="#smoothstep" class="headerlink" title="smoothstep()"></a>smoothstep()</h2><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//表示 r3.w = smoothstep(r3.w, 0, 1);</span></span><br><span class="line">mad r7.x, r3.w, l(<span class="number">-2.0000</span>), l(<span class="number">3.0000</span>)</span><br><span class="line">mul r3.w, r3.w, r3.w</span><br><span class="line">mul r3.w, r3.w, r7.x</span><br><span class="line">或者</span><br><span class="line">dp3 r0.w, r0.xyzx, r0.xyzx</span><br><span class="line">rsq r0.w, r0.w</span><br><span class="line">mul r0.xyz, r0.wwww, r0.xyzx</span><br></pre></td></tr></table></figure><h2 id="normalize"><a href="#normalize" class="headerlink" title="normalize()"></a>normalize()</h2><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//表示r14.xyz = normalize(cb2[3].xyz);</span></span><br><span class="line">dp3 r1.x, cb2[<span class="number">3</span>].xyzx, cb2[<span class="number">3</span>].xyzx</span><br><span class="line">sqrt r1.x, r1.x</span><br><span class="line">div r14.xyz, cb2[<span class="number">3</span>].xyzx, r1.xxxx</span><br></pre></td></tr></table></figure><h2 id="lerp"><a href="#lerp" class="headerlink" title="lerp()"></a>lerp()</h2><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">85</span>: <span class="keyword">add</span> r2.xyz, cb0[<span class="number">9</span>].xyzx, -cb0[<span class="number">10</span>].xyzx</span><br><span class="line"><span class="number">86</span>: mad r2.xyz, r0.zzzz, r2.xyzx, cb0[<span class="number">10</span>].xyzx</span><br><span class="line"><span class="comment">//相当于r2.xyz = lerp(cb0[9].xyz, cb0[10].xyz, r0.z)</span></span><br><span class="line">        </span><br><span class="line"><span class="number">78</span>: mad r1.y, r1.y, cb0[<span class="number">26</span>].w, -cb0[<span class="number">26</span>].w</span><br><span class="line"><span class="number">79</span>: <span class="keyword">add</span> r1.y, r1.y, l(<span class="number">1.0000</span>)</span><br><span class="line"><span class="comment">//相当于r1.y = lerp(r1.y, 1, cb0[26].w)</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Physically Based Volume Rendering(一)</title>
      <link href="/2023/07/08/The%20Equation%20of%20Transfer/"/>
      <url>/2023/07/08/The%20Equation%20of%20Transfer/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>这一章节，我们需要了解光与介质之间的相互作用关系，以及如何用数学公式表示，并且学习Volume Rendering Equation。</p><p>下面有三个我们主要会讨论的物理现象。分别是吸收(absorption)，散射(scattering)，发光(emission)</p><p><img src="1.jpg" alt></p><p>烟雾呈现黑色是因为光被大量的吸收。云朵呈现白色是因为各个波段的光都被散射出来。爆炸产生的蘑菇云中的红色光芒是燃烧产生的光。</p><p>在表示介质的时候，我们通常用 每单位行进距离 的 碰撞密度 来表示介质的性质。</p><p>一些介质会有吸收的性质，当光线朝着给定方向前进一个微分距离，其radiance会减少。减少的比例取决于吸收系数，这个吸收系数量化的是介质在每单位距离吸收光的概率密度。（the probability density of light being absorbed per unit distance）<br>用公式表示就是</p><script type="math/tex; mode=display">\frac{dL }{ dz } = -\mu_a(x)L(x,\omega)</script><p>$\mu_a(x)$表示的是$x$点的吸收系数</p><p>$L（x,\omega）$表示在$x$点$\omega$方向上的radiance</p><p>$dL$表示radiance的变化量</p><p>$dz$表示光线前进的距离</p><p><img src="2.jpg" alt="吸收"></p><p>而如果是具有散射性质的介质，一部分入射光会被散射出去，偏离最初的传播方向。</p><p>与吸收类似，这些散射掉的光的比例与一个系数（散射系数）成正比。这个系数量化的是 这个介质 每单位距离的散射碰撞的概率密度（quantifies the probability density of a scattering collision per  unit distance. ），这是从最初方向被散射出去的光我们称之为 out-scatting radiance</p><p>数学公式为：</p><script type="math/tex; mode=display">\frac{dL }{ dz } = -\mu_s(x)L(x,\omega)</script><p>$\mu_s(x)$为散射系数</p><p><img src="3.jpg" alt="散射"></p><p> 既然某一路径上的光会被向外散射，那么就会有别的路径上的光被散射到我们的目标路径上。这部分光会增加目标路径上的radiance，我们称之为 in-scattering radiance。</p><p>数学公式为：</p><script type="math/tex; mode=display">\frac{dL }{ dz } = -\mu_s(x)L_s(x,\omega)</script><p>$\mu_s(x)$为散射系数</p><p>$L_s(x,\omega)$为$x$点的内散射radiance</p><script type="math/tex; mode=display">L_s(y,\omega) = \int_sf_p(\omega,\overline\omega)L(y,\overline\omega)d\overline\omega</script><p><img src="4.jpg" alt></p><p>最后，发光的介质也会让radiance增加</p><p>数学公式为：</p><script type="math/tex; mode=display">\frac{dL}{dz} = \mu_a(x)L_e(x,\omega)</script><p>$l_e(x,\omega)$是发光radiance</p><p>$\mu_a(x)$是吸收系数</p><p>这里把发光的公式建模为了发光radiance与吸收系数的乘积，这不是必须的，其他的建模方式可能也是合理的。不过有两个原因……</p><p>至此我们讨论了光线传播过程中的吸收，内散射，外散射，介质自发光四种情况，现在我们把所有损失的radiance和得到的radiance合并到一个微分方程中，就得到了所谓的 radiative transfer equation（RTE）</p><script type="math/tex; mode=display">\frac{dL(x,\omega)}{dz}=-\mu_aL(x,\omega)-\mu_sL(x,\omega)+\mu_aL_e(x,\omega)+\mu_sLs(x,\omega)</script><p>我们观察公式中减少radiance的部分，也就是吸收和外散射部分，会发现他们都是对$L(x,\omega)$作用，那么我们可以把这两个项进行合并。</p><p>我们定义$\mu_t=\mu_a+\mu_s$,称之为消隐系数（extinction coefficient），这个系数描述的是每单位距离任意的概率密度（the probability density of any collision per unit distance）</p><p>然后我们得到公式：</p><script type="math/tex; mode=display">\frac{dL(x,\omega)}{dz}=-\mu_tL(x,\omega)+\mu_aL_e(x,\omega)+\mu_sLs(x,\omega)</script><p>接下来，我们沿着$\omega$方向对方程两边进行积分，得到RTE的积分形式</p><script type="math/tex; mode=display">L(x,\omega)=\int_0^zT(x,y)[\mu_aL_e(x,\omega)+\mu_sLs(x,\omega)]dy</script><script type="math/tex; mode=display">T（x,y）=e^{-\int_0^y\mu_t(s)ds}</script><script type="math/tex; mode=display">\tau(x,y) = \int_0^y\mu_t(s)ds</script><p>$T（x,y）$是透射率函数（The transmittance function）</p><p>$\tau(x,y)$是光学深度（The optical thickness）</p><p>透射率函数 量化的是 光从一个点传播到另一个点后，所剩余的光的比例。这个函数的推导被称为The Beer-Lambert law。这个函数告诉我们，光的衰减是呈指数级的。light  is reduced exponentially as a function of negative optical thickness.</p><p>光学深度 是消隐系数 在射线上的积分，光学深度描述的是光在x和y点之间可能进行交互的所有介质的性质。The optical thickness is the integral of the extinction coefficient along the ray and it represents all the material that light could potentially interact with in-between x and y</p><p>从公式可知，我们沿着射线方向进行积分，对于每一个y点，我们都需要评估增益，并且通过透射率函数对其进行加权。</p><p><img src="7.jpg" alt></p><p>TODO：透射率函数与光学深度的推导</p><p>关注完光的削弱部分，我们再回顾到光的增益部分。</p><p><img src="8.jpg" alt></p><p>自发光部分之前已经说明的足够详细，但是内散射部分的公式我们之前只是一笔带过。接下来我们再说一说内散射的公式</p><script type="math/tex; mode=display">L_s(y,\omega) = \int_sf_p(\omega,\overline\omega)L(y,\overline\omega)d\overline\omega</script><p>从公式可以看出，内散射的结果首先是需要对球面上的所有方向进行积分。</p><p>$L（y，\overline\omega）$表示从当前积分的方向来的radaiance</p><p>$f_p(\omega,\overline\omega)$表示的是相位函数（the phase function）</p><p>所谓相位函数，描述的是散射光的方向分布，也就是光如何被散射。如下图</p><p><img src="9.jpg" alt></p><p>不同的相位函数所带来的结果不同，举个例子。</p><p><img src="10.jpg" alt></p><p><img src="11.jpg" alt></p><p>到此为止我们的公式其实还不完整，我们还需要加上射线末端的物体表面提供的radiance。我们称之为background radiance。具体做法是取到表面的radiance，乘以透射函数。加上background radiance之后，公式就完整了</p><script type="math/tex; mode=display">L(x,\omega)=\int_0^zT(x,y)[\mu_aL_e(x,\omega)+\mu_sLs(x,\omega)]dy + T(x,y)L_o(z,\omega)</script><p>这个公式也被称为体积渲染方程 This equation here is often referred to as the volume rendering equation (VRE)</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.pbr-book.org/3ed-2018/Light_Transport_II_Volume_Rendering/The_Equation_of_Transfer?tdsourcetag=s_pcqq_aiomsg">Physically Based Rendering</a></p><p><a href="https://cs.dartmouth.edu/wjarosz/publications/novak18monte-sig.html#downloads">Monte Carlo methods for physically based volume rendering</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
